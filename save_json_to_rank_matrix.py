"""Script to convert json data into a ranking matrix and save."""

import os
import json
from datetime import datetime

import yaml
from absl import app
from absl import flags
from typing import Any, Optional

import numpy as np
import pandas as pd

flags.DEFINE_string(
    "config_file_path",
    "./configs/data_config.yaml",
    "Path to the config file for generating ranking data.",
)

FLAGS = flags.FLAGS


def _increment_ranking_matrix(
    matrix,
    object_set_1: dict[str, Any],
    object_set_2: Optional[dict[str, Any]],
    column_id: int,
):
    """Add a rearrangement scene cluster to the ranking matrix.

    This script generates separate ranking matrices for positive and negative
    object pairs. If only object_set_1 is provided, all object combinations from
    this set are positive pairs, else object combinations across object sets are
    negative pairs.

    Args:
        matrix: Ranking matrix to update.
        object_set_1: First group of objects in the scene.
        object_set_2: Second group of objects in the scene. Defaults to None if
            we are updating the positive matrix.
        column_id: Column ID to update. This depends on the schema corresponding
            to the scene.
    """

    if object_set_2 is None:
        for index, obj_1 in enumerate(object_set_1):
            for obj_2 in object_set_1[index + 1 :]:
                row_id = objcomb2row(obj_1, obj_2)
                matrix[row_id, column_id] = 1

    else:
        for obj_1 in object_set_1:
            for obj_2 in object_set_2:
                row_id = objcomb2row(obj_1, obj_2)
                matrix[row_id, column_id] = 0


def generate_ranking_matrix(json_examples, schemas_list):
    """Generate a pairwise ranking matrix from the json data.

    The pairwise ranking matrix is generated by combining separate count
    matrices for positive and negative object pairs.

    Args:
        json_examples: JSON data of goal scenes.
        schemas_list: List of schemas in the dataset.
    """

    global schemas2col
    global object_combinations

    positive_ranking_matrix = np.zeros((len(object_combinations), len(schemas_list)))
    negative_ranking_matrix = np.zeros((len(object_combinations), len(schemas_list)))

    for scene in json_examples.values():
        schema = scene["rule"]
        goal_scene = scene["goal"]["scene"]

        container_ids = [key for key in goal_scene.keys() if key != "table"]

        schema_column_id = schemas2col(schema)

        for cid in container_ids:
            _increment_ranking_matrix(
                positive_ranking_matrix,
                object_set_1=goal_scene[cid],
                object_set_2=None,
                column_id=schema_column_id,
            )

        for i, cid_1 in enumerate(container_ids):
            for cid_2 in container_ids[i + 1 :]:
                _increment_ranking_matrix(
                    negative_ranking_matrix,
                    object_set_1=goal_scene[cid_1],
                    object_set_2=goal_scene[cid_2],
                    column_id=schema_column_id,
                )

    # -1 means the rating does not exist
    final_ranking_matrix = -1 * np.ones(
        (len(object_combinations), len(schemas_list))
    )

    number_noratings = 0
    number_conflicting = 0
    for row in range(len(object_combinations)):
        for col in range(len(schemas_list)):
            # If either the rating does not exist (both 0) or there are
            # conflicting ratings (both 1).
            if (
                negative_ranking_matrix[row, col]
                == positive_ranking_matrix[row, col]
                == 1
            ):
                final_ranking_matrix[
                    row, col
                ] == 0.5  # objects may or may not be together.
                number_conflicting += 1

            elif (
                negative_ranking_matrix[row, col]
                == positive_ranking_matrix[row, col]
                == 0
            ):
                # do nothing.
                number_noratings += 1

            elif negative_ranking_matrix[row, col] == 1:
                # objects are placed separately.
                final_ranking_matrix[row, col] = 0

            elif positive_ranking_matrix[row, col] == 1:
                # objects are grouped together.
                final_ranking_matrix[row, col] = 1

    print(f"Number of absent ratings: {number_noratings}")
    print(f"Number of conflicting ratings: {number_noratings}")

    return final_ranking_matrix


def objcomb2row(obj1, obj2):
    """Returns the row index of the object combination in the ranking matrix.

    Args:
        obj1: Name of first object in the combination.
        obj2: Name of second object in the combination.
    Raises:
        KeyError: If the object combination does not exist.
    """

    global object_combinations

    for i, objtup in enumerate(object_combinations):
        if (obj1, obj2) == objtup or (obj2, obj1) == objtup:
            return i
    raise KeyError(f"{obj1}-{obj2} combination does not exist in list")


def main(argv):
    if len(argv) > 1:
        raise app.UsageError("Too many command-line arguments.")

    global schemas2col
    global object_combinations

    # Load config.
    with open(FLAGS.config, "r") as fh:
        config = yaml.safe_load(fh)
        config = config["DATA"]

    train_json_file = os.path.join(
        config["json_data_folder"],
        f'consor_{config["json_seen_objects_timestamp"]}_seen_objects_train.json',
    )
    val_json_file = os.path.join(
        config["json_data_folder"],
        f'consor_{config["json_seen_objects_timestamp"]}_seen_objects_val.json',
    )  

    folder_tag = config["json_seen_objects_timestamp"]
    destination_folder = config["destination_folder"]

    with open(train_json_file, "r") as fh:
        train_examples = json.load(fh)

    with open(val_json_file, "r") as fh:
        val_examples = json.load(fh)

    folder_tag += "_seen-objs"

    # Load seen objects.
    objects_df = pd.read_csv(config["objects_list"])

    objects_seen_df = objects_df[objects_df["Seen/Unseen"] == "Seen"]
    filtered_objects = list(objects_seen_df["ObjectName"])

    # Generate object combinations from list of seen objects.
    object_combinations = []
    for i, obj_i in enumerate(filtered_objects):
        for obj_j in filtered_objects[i:]:  # allow combinations with self.
            object_combinations.append((obj_i, obj_j))
    print(f"Number of object combinations: {len(object_combinations)}")

    # Save object combinations, while removing last comma.
    with open(
        os.path.join(
            config["destination_folder"], f"object_combinations_{folder_tag}.txt"
        ),
        "w",
    ) as fh:
        for objcomb in object_combinations:
            fh.write(f"{objcomb[0]},{objcomb[1]}\n")

    schemas_list = config["schemas"].split(",")  # list of schemas in the dataset
    schemas2col_dict = dict({schema: i for i, schema in enumerate(schemas_list)})
    schemas2col = lambda x: schemas2col_dict[x]

    final_ranking_matrix_train = generate_ranking_matrix(train_examples, schemas_list)
    np.save(
        os.path.join(
            destination_folder, f"consor_ranking_matrix_train_{folder_tag}.npy"
        ),
        final_ranking_matrix_train,
    )
    print("Saved training ranking matrix")

    final_ranking_matrix_val = generate_ranking_matrix(val_examples, schemas_list)
    np.save(
        os.path.join(destination_folder, f"consor_ranking_matrix_val_{folder_tag}.npy"),
        final_ranking_matrix_val,
    )
    print("Saved validation ranking matrix")


if __name__ == "__main__":
    app.run(main)
